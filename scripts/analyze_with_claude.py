#!/usr/bin/env python3
"""
ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æã‚’Claude APIã§å¼·åŒ–ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é€±1å›ã®å®Ÿè¡Œã‚’æƒ³å®šã—ãŸé«˜åº¦ãªåˆ†ææ©Ÿèƒ½
"""

import json
import os
import sys
import subprocess
from typing import Dict, List, Any, Optional
from datetime import datetime
import anthropic
from pathlib import Path

class ClaudeCodeAnalyzer:
    def __init__(self):
        api_key = os.environ.get('ANTHROPIC_API_KEY')
        if not api_key:
            print("Error: ANTHROPIC_API_KEY environment variable not set")
            sys.exit(1)
        
        self.client = anthropic.Anthropic(api_key=api_key)
        self.project_root = Path.cwd()
        
    def collect_static_analysis(self) -> Dict[str, Any]:
        """é™çš„åˆ†æçµæœã‚’åé›†"""
        analysis_data = {
            'timestamp': datetime.now().isoformat(),
            'typescript_errors': self._get_typescript_errors(),
            'eslint_issues': self._get_eslint_issues(),
            'test_coverage': self._get_test_coverage(),
            'code_metrics': self._analyze_code_metrics(),
            'large_files': self._find_large_files(),
            'any_usage': self._find_any_usage(),
        }
        return analysis_data
    
    def _get_typescript_errors(self) -> List[Dict[str, Any]]:
        """TypeScriptã‚¨ãƒ©ãƒ¼ã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ['npx', 'tsc', '--noEmit'],
                capture_output=True,
                text=True
            )
            errors = []
            for line in result.stdout.splitlines():
                if '.ts' in line and ':' in line:
                    errors.append({'error': line.strip()})
            return errors[:50]  # æœ€åˆã®50ä»¶ã®ã¿
        except:
            return []
    
    def _get_eslint_issues(self) -> Dict[str, int]:
        """ESLintå•é¡Œã‚’å–å¾—"""
        try:
            result = subprocess.run(
                ['npx', 'eslint', 'src', '--format', 'json'],
                capture_output=True,
                text=True
            )
            data = json.loads(result.stdout)
            total_errors = sum(r['errorCount'] for r in data)
            total_warnings = sum(r['warningCount'] for r in data)
            return {
                'errors': total_errors,
                'warnings': total_warnings,
                'total': total_errors + total_warnings
            }
        except:
            return {'errors': 0, 'warnings': 0, 'total': 0}
    
    def _get_test_coverage(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å–å¾—"""
        # ç°¡æ˜“å®Ÿè£… - å®Ÿéš›ã«ã¯npm test -- --coverageã®çµæœã‚’è§£æ
        return {
            'overall': 60.0,
            'uncovered_files': [
                'src/utils/encoding-detector.ts',
                'src/utils/logger.ts',
                'src/lib/config.ts'
            ]
        }
    
    def _analyze_code_metrics(self) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åˆ†æ"""
        total_files = 0
        total_lines = 0
        
        for ext in ['*.ts', '*.tsx']:
            files = list(self.project_root.rglob(ext))
            total_files += len(files)
            for file in files:
                if 'node_modules' not in str(file):
                    try:
                        total_lines += len(file.read_text().splitlines())
                    except:
                        pass
        
        return {
            'total_files': total_files,
            'total_lines': total_lines,
            'average_file_size': total_lines / total_files if total_files > 0 else 0
        }
    
    def _find_large_files(self) -> List[Dict[str, Any]]:
        """600è¡Œã‚’è¶…ãˆã‚‹å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        large_files = []
        for file in self.project_root.rglob('*.ts'):
            if 'node_modules' not in str(file):
                try:
                    lines = len(file.read_text().splitlines())
                    if lines > 600:
                        large_files.append({
                            'path': str(file.relative_to(self.project_root)),
                            'lines': lines
                        })
                except:
                    pass
        return sorted(large_files, key=lambda x: x['lines'], reverse=True)
    
    def _find_any_usage(self) -> Dict[str, Any]:
        """anyå‹ã®ä½¿ç”¨çŠ¶æ³ã‚’æ¤œç´¢"""
        any_count = 0
        files_with_any = []
        
        for file in self.project_root.rglob('*.ts'):
            if 'node_modules' not in str(file):
                try:
                    content = file.read_text()
                    count = content.count(': any')
                    if count > 0:
                        any_count += count
                        files_with_any.append({
                            'path': str(file.relative_to(self.project_root)),
                            'count': count
                        })
                except:
                    pass
        
        return {
            'total_count': any_count,
            'files': sorted(files_with_any, key=lambda x: x['count'], reverse=True)[:10]
        }
    
    def analyze_with_claude(self, analysis_data: Dict[str, Any], options: Dict[str, bool]) -> Dict[str, Any]:
        """Claude APIã§é«˜åº¦ãªåˆ†æã‚’å®Ÿè¡Œ"""
        
        # åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        if options.get('refactor'):
            return self._analyze_refactoring(analysis_data)
        elif options.get('test_generation'):
            return self._analyze_test_generation(analysis_data)
        else:
            return self._analyze_architecture(analysis_data)
    
    def _analyze_architecture(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æã¨æ”¹å–„ææ¡ˆ"""
        prompt = f"""
ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®TypeScriptãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åˆ†æçµæœã‚’ç¢ºèªã—ã€
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµ±è¨ˆ:
- ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {data['code_metrics']['total_files']}
- ç·è¡Œæ•°: {data['code_metrics']['total_lines']}
- TypeScriptã‚¨ãƒ©ãƒ¼: {len(data['typescript_errors'])}ä»¶
- ESLintã‚¨ãƒ©ãƒ¼: {data['eslint_issues']['errors']}ä»¶
- ESLintè­¦å‘Š: {data['eslint_issues']['warnings']}ä»¶
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {data['test_coverage']['overall']}%
- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«(600è¡Œè¶…): {len(data['large_files'])}å€‹
- anyå‹ä½¿ç”¨: {data['any_usage']['total_count']}ç®‡æ‰€

å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«:
{json.dumps(data['large_files'][:5], indent=2)}

ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„:
1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ç‚¹ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ï¼‰
2. å“è³ªã‚¹ã‚³ã‚¢ã‚’6.8/10ã‹ã‚‰8.0/10ã«å‘ä¸Šã•ã›ã‚‹å…·ä½“çš„ãªæ‰‹é †
3. æŠ€è¡“çš„è² å‚µã®å„ªå…ˆé †ä½ä»˜ã‘
4. ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¨ã®å·®åˆ†
5. æ®µéšçš„ãªæ”¹å–„è¨ˆç”»ï¼ˆ1é€±é–“ã€1ãƒ¶æœˆã€3ãƒ¶æœˆï¼‰

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = self.client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4000,
            temperature=0,
            messages=[{"role": "user", "content": prompt}]
        )
        
        try:
            return json.loads(response.content[0].text)
        except:
            return {'analysis': response.content[0].text}
    
    def _analyze_refactoring(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆ"""
        prompt = f"""
ã‚ãªãŸã¯ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€
å…·ä½“çš„ãªåˆ†å‰²æ–¹æ³•ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«:
{json.dumps(data['large_files'], indent=2)}

anyå‹ã®ä½¿ç”¨çŠ¶æ³:
{json.dumps(data['any_usage']['files'][:5], indent=2)}

ä»¥ä¸‹ã‚’å«ã‚ã¦ææ¡ˆã—ã¦ãã ã•ã„:
1. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²æ¡ˆï¼ˆã©ã®ã‚ˆã†ã«æ©Ÿèƒ½ã‚’åˆ†ã‘ã‚‹ã‹ï¼‰
2. anyå‹ã‚’å…·ä½“çš„ãªå‹ã«ç½®ãæ›ãˆã‚‹æ–¹æ³•
3. å…±é€šåŒ–ã§ãã‚‹ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
4. ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®å„ªå…ˆé †ä½
5. å„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã®æƒ³å®šä½œæ¥­æ™‚é–“

JSONå½¢å¼ã§ã€å®Ÿè£…å¯èƒ½ãªå…·ä½“çš„ãªææ¡ˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚
"""
        
        response = self.client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=4000,
            temperature=0,
            messages=[{"role": "user", "content": prompt}]
        )
        
        try:
            return json.loads(response.content[0].text)
        except:
            return {'refactoring': response.content[0].text}
    
    def _analyze_test_generation(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆç”Ÿæˆææ¡ˆ"""
        prompt = f"""
ã‚ãªãŸã¯ãƒ†ã‚¹ãƒˆè¨­è¨ˆã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸æƒ…å ±ã‚’åŸºã«ã€
ãƒ†ã‚¹ãƒˆæ”¹å–„è¨ˆç”»ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®ã‚«ãƒãƒ¬ãƒƒã‚¸: {data['test_coverage']['overall']}%
ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«:
{json.dumps(data['test_coverage']['uncovered_files'], indent=2)}

ä»¥ä¸‹ã‚’ææ¡ˆã—ã¦ãã ã•ã„:
1. å„ªå…ˆçš„ã«ãƒ†ã‚¹ãƒˆã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ã¨ãã®ç†ç”±
2. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä¾‹ï¼ˆ3ã¤ãšã¤ï¼‰
3. E2Eãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªï¼ˆä¸»è¦ãª5ã¤ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ­ãƒ¼ï¼‰
4. ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’85%ã«ä¸Šã’ã‚‹ãŸã‚ã®æ®µéšçš„è¨ˆç”»
5. ãƒ¢ãƒƒã‚¯ã¨ã‚¹ã‚¿ãƒ–ã®æˆ¦ç•¥

JSONå½¢å¼ã§ã€å®Ÿè£…å¯èƒ½ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
"""
        
        response = self.client.messages.create(
            model="claude-3-haiku-20240307",  # ãƒ†ã‚¹ãƒˆç”Ÿæˆã¯å®‰ä¾¡ãªãƒ¢ãƒ‡ãƒ«ã§ååˆ†
            max_tokens=4000,
            temperature=0.2,
            messages=[{"role": "user", "content": prompt}]
        )
        
        try:
            return json.loads(response.content[0].text)
        except:
            return {'test_plan': response.content[0].text}
    
    def generate_report(self, analysis_result: Dict[str, Any], output_file: str = '.claude/ai-analysis-report.md'):
        """åˆ†æçµæœã‚’Markdownãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ç”Ÿæˆ"""
        report = f"""# ğŸ¤– AIå¼·åŒ–ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼

### é™çš„åˆ†æçµæœ
- TypeScriptã‚¨ãƒ©ãƒ¼: {len(self.analysis_data.get('typescript_errors', []))}ä»¶
- ESLintå•é¡Œ: {self.analysis_data['eslint_issues']['total']}ä»¶
- ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸: {self.analysis_data['test_coverage']['overall']}%
- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«: {len(self.analysis_data['large_files'])}å€‹
- anyå‹ä½¿ç”¨: {self.analysis_data['any_usage']['total_count']}ç®‡æ‰€

## ğŸ¯ AIåˆ†æçµæœ

"""
        
        # AIåˆ†æçµæœã‚’æ•´å½¢ã—ã¦è¿½åŠ 
        if isinstance(analysis_result, dict):
            for key, value in analysis_result.items():
                report += f"### {key.replace('_', ' ').title()}\n\n"
                if isinstance(value, list):
                    for item in value:
                        report += f"- {item}\n"
                elif isinstance(value, dict):
                    report += "```json\n"
                    report += json.dumps(value, indent=2, ensure_ascii=False)
                    report += "\n```\n"
                else:
                    report += f"{value}\n"
                report += "\n"
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(report, encoding='utf-8')
        
        print(f"âœ… åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_file}")
        return report
    
    def estimate_cost(self, options: Dict[str, bool]) -> float:
        """APIä½¿ç”¨ã‚³ã‚¹ãƒˆã‚’æ¦‚ç®—"""
        # æ¦‚ç®—: å„åˆ†æã§ç´„10K-20Kãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹ã¨ä»®å®š
        if options.get('refactor') or options.get('test_generation'):
            # Haikuãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
            return 0.25 * 0.02  # $0.25/1M tokens * 20K tokens
        else:
            # Sonnetãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
            return 3.0 * 0.02  # $3/1M tokens * 20K tokens

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Claude APIã§ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’é«˜åº¦ã«åˆ†æ')
    parser.add_argument('--with-ai', action='store_true', help='Claude APIã«ã‚ˆã‚‹é«˜åº¦åˆ†æ')
    parser.add_argument('--refactor', action='store_true', help='ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆ')
    parser.add_argument('--test-generation', action='store_true', help='ãƒ†ã‚¹ãƒˆç”Ÿæˆææ¡ˆ')
    parser.add_argument('--output', default='.claude/ai-analysis-report.md', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--dry-run', action='store_true', help='ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šã®ã¿')
    
    args = parser.parse_args()
    
    analyzer = ClaudeCodeAnalyzer()
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
    options = {
        'refactor': args.refactor,
        'test_generation': args.test_generation,
        'with_ai': args.with_ai or args.refactor or args.test_generation
    }
    
    # ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š
    if args.dry_run:
        cost = analyzer.estimate_cost(options)
        print(f"æ¨å®šã‚³ã‚¹ãƒˆ: ${cost:.4f}")
        return
    
    # é™çš„åˆ†æå®Ÿè¡Œ
    print("ğŸ“Š é™çš„åˆ†æã‚’å®Ÿè¡Œä¸­...")
    analyzer.analysis_data = analyzer.collect_static_analysis()
    
    # AIåˆ†æå®Ÿè¡Œ
    if options['with_ai']:
        print("ğŸ¤– Claude APIã§é«˜åº¦ãªåˆ†æã‚’å®Ÿè¡Œä¸­...")
        result = analyzer.analyze_with_claude(analyzer.analysis_data, options)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        analyzer.generate_report(result, args.output)
        
        # çµæœã®è¦ç´„ã‚’è¡¨ç¤º
        print("\nğŸ“‹ åˆ†æå®Œäº†ï¼ä¸»ãªææ¡ˆ:")
        if isinstance(result, dict):
            for i, (key, value) in enumerate(list(result.items())[:3]):
                print(f"{i+1}. {key}: {str(value)[:100]}...")
    else:
        # é™çš„åˆ†æã®ã¿
        print("âœ… é™çš„åˆ†æå®Œäº†")
        print(f"- TypeScriptã‚¨ãƒ©ãƒ¼: {len(analyzer.analysis_data['typescript_errors'])}ä»¶")
        print(f"- ESLintå•é¡Œ: {analyzer.analysis_data['eslint_issues']['total']}ä»¶")
        print(f"- å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«: {len(analyzer.analysis_data['large_files'])}å€‹")

if __name__ == '__main__':
    main()